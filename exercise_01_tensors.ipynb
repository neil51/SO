{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neil51/SO/blob/main/exercise_01_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvHn3_EOLz3"
      },
      "source": [
        "# 1 Tensors\n",
        "\n",
        "In chapter *1 - Introduction* of the lecture, we recapitulated tensor notation and tensor analysis. In this exercise, we will gain some more confidence in working with tensors on paper, but also in code. \n",
        "\n",
        "To solve the tasks with code, we will use PyTorch, a powerful Python package to operate on tensors. In comparison to NumPy, it stores gradients together with tensors and thus allows automatic differentiation. The package is used widely for machine learning and optimization. For installation it is best to create a new conda environement via\n",
        "```\n",
        "    conda create -n pytorch python=3.10\n",
        "```\n",
        "we can than activate that environment\n",
        "```\n",
        "    conda activate pytorch\n",
        "``` \n",
        "and then use \n",
        "```\n",
        "    conda install matplotlib pytorch torchvision jupyter jupyter-lab\n",
        "```\n",
        "to install the required packages. After that, you should be able to import the torch package in a Jupyter Notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gnR-oBaCOLz4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.set_default_dtype(torch.double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K56ZoUT8OLz5"
      },
      "source": [
        "## Task 1 - Vector products\n",
        "\n",
        "Given two vectors $\\mathbf{a}, \\mathbf{b} \\in \\mathcal{R}^3$ with\n",
        "$$\n",
        "\\mathbf{a} = \\begin{pmatrix}2\\\\1\\\\3\\end{pmatrix} \\quad \\mathbf{b} = \\begin{pmatrix}5\\\\0\\\\1\\end{pmatrix}\n",
        "$$\n",
        "define the vectors in torch and compute the scalar product, cross product and outer product. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ob9E6ilDOLz5"
      },
      "outputs": [],
      "source": [
        "# --> define a \n",
        "a = torch.Tensor([2.0, 1.0, 3.0])\n",
        "\n",
        "# --> define b\n",
        "b = torch.Tensor([5.0, 0.0, 1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print a\n",
        "print(a)"
      ],
      "metadata": {
        "id": "Ol-oVqKRP2lU",
        "outputId": "fb3384f2-1af2-472f-8442-6a7547761db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 1., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print b\n",
        "print(b)"
      ],
      "metadata": {
        "id": "d3kMT-hPQAhr",
        "outputId": "408717f6-7ed7-47d1-a9f0-926de4755a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP32EE9tOLz5",
        "outputId": "7439c62e-4168-4a67-cb70-501889d583d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner product:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(\"Inner product:\")\n",
        "# --> compute inner product\n",
        "torch.inner(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMPlNUXxOLz6",
        "outputId": "603383fa-e9c0-4c1e-8222-491ecec63fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross product:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1., 13., -5.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "print(\"Cross product:\")\n",
        "# --> compute cross product\n",
        "torch.cross(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRydjygrOLz6",
        "outputId": "90fa21a4-b25b-44e1-de4c-29f58e2b9e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outer product:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.,  0.,  2.],\n",
              "        [ 5.,  0.,  1.],\n",
              "        [15.,  0.,  3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "print(\"Outer product:\")\n",
        "# --> compute outer product\n",
        "torch.outer(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkpMtK3TOLz6"
      },
      "source": [
        "## Task 2 - Tensor products\n",
        "Given the tensors $\\mathbf{A}, \\mathbf{B} \\in \\mathcal{R}^{3 \\times 3}$ and $\\mathbb{C} \\in \\mathcal{R}^{3 \\times 3 \\times 3 \\times 3}$ convert the following expressions to sums of components and determine the dimensions of the resulting tensor. \n",
        "\n",
        "Example: \n",
        "\n",
        "$$\\mathbf{A} \\cdot \\mathbf{b} \\rightarrow \\sum_{i,j} A_{ij}b_j \\mathbf{e}_j$$\n",
        "\n",
        "a)  $$\\mathbf{a} \\cdot \\mathbf{A} \\cdot \\mathbf{b}$$\n",
        "b) $$\\mathbf{b} \\cdot \\mathbf{A} \\cdot \\mathbf{a}$$\n",
        "c) $$\\mathbf{A} \\cdot \\mathbf{B} \\cdot \\mathbf{b}$$\n",
        "d) $$(\\mathbf{A} : \\mathbf{B}) \\mathbf{b}$$\n",
        "e) $$(\\mathbf{a} \\otimes \\mathbf{b}) : \\mathbf{B}$$\n",
        "f) $$\\mathbf{A} \\otimes \\mathbb{C} : \\mathbf{B}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny9d9t0BOLz6"
      },
      "source": [
        "> Calculate results by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8WQ9Oh7OLz7"
      },
      "source": [
        "Convert the following expressions to symbolic notation and determine the dimensions of the resulting tensor: \n",
        "\n",
        "g) $$\\sum_{z,j} A_{zj}b_z \\mathbf{e}_j$$\n",
        "h) $$\\sum_{i,j,k} A_{ij}B_{jk}a_k \\mathbf{e}_i$$\n",
        "i) $$\\sum_{m,n,o,p,i} C_{mnop}A_{po}\\delta_{ni}a_{i} \\mathbf{e}_m$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvIMiRaiOLz7"
      },
      "source": [
        "> Calculate results by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3EVSgndOLz7"
      },
      "source": [
        "Given the values \n",
        "$$\n",
        "\\mathbf{A} = \n",
        "\\begin{pmatrix}\n",
        "    6 & 2 & 1\\\\\n",
        "    4 & 7 & 6\\\\\n",
        "    0 & 2 & 9\n",
        "\\end{pmatrix} \n",
        "\\quad \n",
        "\\mathbf{B} = \n",
        "\\begin{pmatrix}\n",
        "    5 & 7 & 11\\\\\n",
        "    0 & 4 & 3\\\\\n",
        "    1 & 2 & 9\n",
        "\\end{pmatrix}\n",
        "\\quad \n",
        "C_{ijkl} = 1 \\forall i,j,k,l\n",
        "$$\n",
        "define the tensors in torch and compute the expressions above. Reuse $\\mathbf{a}$ and $\\mathbf{b}$ from the first task.\n",
        "\n",
        "*Tips:* \n",
        "- What we denote with $\\cdot$ in the lecture, can be written with an `@` or `torch.tensordot(...,dim=1)`  in numpy and torch.\n",
        "- What we denote with $:$ in the lhe lecture, can be written with `torch.tensordot` in numpy and torch.\n",
        "- Multiplication between scalars is done simply by `*`.\n",
        "- We can use `torch.einsum()` to define arbitrary expressions using Einstein's summation convention. Here, the function automatically sums over indices in an expression, e.g. `torch.einsum(\"ij,j->i\",A,b)` computes $\\sum_{ij} A_{ij}b_j \\mathbf{e}_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PA4SSZJuOLz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06eb432b-b0a3-4200-8222-d528d79efb50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(115.)\n",
            "tensor([930.,   0., 186.])\n",
            "tensor(117.)\n",
            "torch.Size([3, 3, 3, 3])\n",
            "tensor([30., 12., 14.])\n",
            "tensor([357., 477., 305.])\n",
            "tensor([222., 222., 222.])\n"
          ]
        }
      ],
      "source": [
        "# --> Define tensors A, B, C\n",
        "A = torch.Tensor([[6., 2., 1.], [4., 7., 6.], [0., 2., 9.]])\n",
        "B = torch.Tensor([[5., 7., 11.], [0., 4., 3.], [1., 2., 9.]])\n",
        "C = torch.ones(3,3,3,3)\n",
        "I = torch.eye(3)\n",
        "\n",
        "# --> Compute products a) to f)\n",
        "print(a @ A @ b)\n",
        "print(torch.tensordot(A,B) * b)\n",
        "print(torch.tensordot(torch.outer(a,b), B))\n",
        "print(torch.einsum(\"ij,klmn,nm\", A,C,B).shape)\n",
        "\n",
        "# --> Compute products g) to i)\n",
        "print(torch.einsum(\"zj,z\", A, b))\n",
        "print(torch.einsum(\"ij, jk, k\", A, B, a))\n",
        "print(torch.einsum(\"mnop, po, ni, i\", C, A, I, a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cO2t8hIOLz7"
      },
      "source": [
        "## Task 3 - Gradients\n",
        "Given the vectorfield $f: \\mathcal{R}^2 \\rightarrow \\mathcal{R}$ defined as \n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = (\\mathbf{x} - \\tilde{\\mathbf{x}}) \\cdot \\mathbf{Q} \\cdot (\\mathbf{x} - \\tilde{\\mathbf{x}})\n",
        "$$\n",
        "with \n",
        "$$\n",
        "\\mathbf{Q} = \n",
        "\\begin{pmatrix}\n",
        "    2 & 1 \\\\\n",
        "    1 & 1 \n",
        "\\end{pmatrix} \n",
        "\\quad \n",
        "\\text{and}\n",
        "\\quad\n",
        "\\tilde{\\mathbf{x}} = \n",
        "\\begin{pmatrix}\n",
        "    -1\\\\\n",
        "    1 \n",
        "\\end{pmatrix}\n",
        "$$\n",
        "compute the gradient analytically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwkthXJ2OLz8"
      },
      "source": [
        "> Compute the gradient by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV-cZFsHOLz8"
      },
      "source": [
        "Doing these computations by hand takes a while. Therefore we take a look at how to compute gradients using PyTorch. To do so, we start by defining $\\mathbf{Q}$, $\\tilde{\\mathbf{x}}$ and the function $f(\\mathbf{x})$. The function $f(\\mathbf{x})$ can be implemented in a straight forward way and you should try a straight forward implementation first. \n",
        "\n",
        "However, we would like to be able to evaluate the function for many values of $\\mathbf{x}$ at the same time. This is equivalent to passing a tensor of the shape $\\mathcal{R}^{... \\times 2}$ with arbitray dimensions except the last axis. This can be implemented using an ellipsis `...` in `torch.einsum()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3C6bptdOLz8"
      },
      "outputs": [],
      "source": [
        "# --> Define Q and x_tilde \n",
        "\n",
        "# --> Define the fucntion f(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajaf_jGEOLz8"
      },
      "source": [
        "If your function is defined correctly, the following cell should plot the function values as a contour plot. It produces an error now, because the function f(x) has not been defined yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljOWJHSGOLz8",
        "outputId": "98a63940-20dd-45a4-e31a-27b887388876"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'f' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m x1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, steps\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(torch\u001b[39m.\u001b[39mmeshgrid(x0, x1, indexing\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mxy\u001b[39m\u001b[39m\"\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m plot_contours(x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m0\u001b[39m], x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m1\u001b[39m], f(x), title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mf(x)\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
          ]
        }
      ],
      "source": [
        "from utils import plot_contours\n",
        "\n",
        "# Define x\n",
        "x0 = torch.linspace(-3, 3, steps=100, requires_grad=True)\n",
        "x1 = torch.linspace(-3, 3, steps=100, requires_grad=True)\n",
        "x = torch.stack(torch.meshgrid(x0, x1, indexing=\"xy\"), dim=2)\n",
        "\n",
        "plot_contours(x[...,0], x[...,1], f(x), title=\"f(x)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuGVU0QyOLz8"
      },
      "source": [
        "Note that the `requires_grad=True` argument defines that these specific tensors will be used in gradient computations. They reserve storage for the tensor data as well as the gradients. Now, lets compute the actual gradients with automatic differentiation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzQTG6J8OLz9",
        "outputId": "15b2f8c9-6ec0-4a07-fd32-9b05f7a4c408"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'f' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfdx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(f(x)\u001b[39m.\u001b[39msum(), x)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m plot_contours(x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m], x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m], dfdx[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m], title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGradient in x_0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plot_contours(x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m], x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m], dfdx[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m], title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGradient in x_1\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
          ]
        }
      ],
      "source": [
        "dfdx = torch.autograd.grad(f(x).sum(), x)[0]\n",
        "\n",
        "plot_contours(x[..., 0], x[..., 1], dfdx[..., 0], title=\"Gradient in x_0\")\n",
        "plot_contours(x[..., 0], x[..., 1], dfdx[..., 1], title=\"Gradient in x_1\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}